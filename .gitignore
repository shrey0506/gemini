# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# PyPI configuration file
.pypirc





import pandas as pd
import re
from PyPDF2 import PdfReader

# Function to parse charity details
def parse_charity_details(text):
    pattern = r"(\d+)\s+(.*?)\n(.*?)\n(.*?)\n(.*?)\s+(http.*?|www\..*?)?\s+(\d{2} [A-Za-z]{3} \d{4})"
    matches = re.findall(pattern, text, re.DOTALL)
    data = []
    for match in matches:
        charity_number = match[0].strip()
        charity_name = match[1].strip()
        objects = match[2].replace("\n", " ").strip()
        address = match[3].replace("\n", " ").strip()
        email = match[4].strip()
        website = match[5].strip() if match[5] else "N/A"
        date_registered = match[6].strip()
        data.append([charity_number, charity_name, objects, address, email, website, date_registered])
    return data

# Load the PDF and extract text
pdf_path = "path_to_your_uploaded_file.pdf"  # Replace with the actual path
reader = PdfReader(pdf_path)
all_text = ""
for page in reader.pages:
    all_text += page.extract_text()

# Parse the details
charity_data = parse_charity_details(all_text)

# Create a DataFrame
columns = ["Table No.", "Charity", "Objects", "Correspondence Address", "Email Address", "Website", "Date Registered"]
df = pd.DataFrame(charity_data, columns=columns)

# Save to CSV
output_csv = "charity_details.csv"
df.to_csv(output_csv, index=False)

print(f"Data extracted and saved to {output_csv}")

To split rows accurately based on the three conditions you provided (email, website, and date), we can identify where these elements appear together in the text and treat that as the boundary for a row. The solution involves using regular expressions to extract and structure the data.

Revised Approach:

1. Define the Row Boundaries:

A row starts when an email is found and ends at the corresponding date.



2. Regex to Match Complete Rows:

A pattern is created to capture the email, optional website, and date in one go.



3. Process and Split Rows:

Use the regex to find all matches in the text and treat each match as a row.




Updated Python Script:

import re
import csv

# Sample text from page 1
text = """
John Doe john.doe@example.com www.example.com 10 Jan 2024
Jane Smith jane.smith@example.com 12 Feb 2024
Adam Johnson adam.j@example.com www.adamjohnson.com 23 Mar 2024
"""

# Define regex pattern to capture rows
row_pattern = re.compile(
    r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'  # Email
    r'(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?'        # Optional website
    r'\s+(\d{1,2} [A-Za-z]{3} \d{4})'                    # Date
)

# Extract rows using the pattern
matches = row_pattern.findall(text)

# Prepare data for CSV
data = []
for match in matches:
    email = match[0]
    website = match[1] if match[1] else ""  # Handle optional website
    date = match[2]
    data.append([email, website, date])

# Save to CSV
csv_file = 'output.csv'
with open(csv_file, 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    # Write header
    writer.writerow(['Email', 'Website', 'Date'])
    # Write rows
    writer.writerows(data)

print(f"Data has been written to {csv_file}")

Explanation:

1. Regex Breakdown:

([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}): Matches the email.

(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?: Optionally matches the website (non-capturing group with ?).

\s+(\d{1,2} [A-Za-z]{3} \d{4}): Matches the date format (e.g., 10 Jan 2024).



2. Findall:

re.findall returns a list of tuples, each containing the captured groups (email, website, and date).



3. Handling Optional Website:

If the website group is empty, it's replaced with an empty string.



4. CSV Writing:

The extracted rows are saved to a CSV file with headers.




Output:

If you run the script with the provided sample text, the generated output.csv will look like this:

This approach ensures the rows are split based on the presence of an email, optional website, and date, rather than relying on newline characters. Let me know if you have more requirements!

To split rows accurately based on the three conditions you provided (email, website, and date), we can identify where these elements appear together in the text and treat that as the boundary for a row. The solution involves using regular expressions to extract and structure the data.

Revised Approach:

1. Define the Row Boundaries:

A row starts when an email is found and ends at the corresponding date.



2. Regex to Match Complete Rows:

A pattern is created to capture the email, optional website, and date in one go.



3. Process and Split Rows:

Use the regex to find all matches in the text and treat each match as a row.




Updated Python Script:

import re
import csv

# Sample text from page 1
text = """
John Doe john.doe@example.com www.example.com 10 Jan 2024
Jane Smith jane.smith@example.com 12 Feb 2024
Adam Johnson adam.j@example.com www.adamjohnson.com 23 Mar 2024
"""

# Define regex pattern to capture rows
row_pattern = re.compile(
    r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'  # Email
    r'(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?'        # Optional website
    r'\s+(\d{1,2} [A-Za-z]{3} \d{4})'                    # Date
)

# Extract rows using the pattern
matches = row_pattern.findall(text)

# Prepare data for CSV
data = []
for match in matches:
    email = match[0]
    website = match[1] if match[1] else ""  # Handle optional website
    date = match[2]
    data.append([email, website, date])

# Save to CSV
csv_file = 'output.csv'
with open(csv_file, 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    # Write header
    writer.writerow(['Email', 'Website', 'Date'])
    # Write rows
    writer.writerows(data)

print(f"Data has been written to {csv_file}")

Explanation:

1. Regex Breakdown:

([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}): Matches the email.

(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?: Optionally matches the website (non-capturing group with ?).

\s+(\d{1,2} [A-Za-z]{3} \d{4}): Matches the date format (e.g., 10 Jan 2024).



2. Findall:

re.findall returns a list of tuples, each containing the captured groups (email, website, and date).



3. Handling Optional Website:

If the website group is empty, it's replaced with an empty string.



4. CSV Writing:

The extracted rows are saved to a CSV file with headers.




Output:

If you run the script with the provided sample text, the generated output.csv will look like this:

This approach ensures the rows are split based on the presence of an email, optional website, and date, rather than relying on newline characters. Let me know if you have more requirements!

To split rows accurately based on the three conditions you provided (email, website, and date), we can identify where these elements appear together in the text and treat that as the boundary for a row. The solution involves using regular expressions to extract and structure the data.

Revised Approach:

1. Define the Row Boundaries:

A row starts when an email is found and ends at the corresponding date.



2. Regex to Match Complete Rows:

A pattern is created to capture the email, optional website, and date in one go.



3. Process and Split Rows:

Use the regex to find all matches in the text and treat each match as a row.




Updated Python Script:

import re
import csv

# Sample text from page 1
text = """
John Doe john.doe@example.com www.example.com 10 Jan 2024
Jane Smith jane.smith@example.com 12 Feb 2024
Adam Johnson adam.j@example.com www.adamjohnson.com 23 Mar 2024
"""

# Define regex pattern to capture rows
row_pattern = re.compile(
    r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'  # Email
    r'(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?'        # Optional website
    r'\s+(\d{1,2} [A-Za-z]{3} \d{4})'                    # Date
)

# Extract rows using the pattern
matches = row_pattern.findall(text)

# Prepare data for CSV
data = []
for match in matches:
    email = match[0]
    website = match[1] if match[1] else ""  # Handle optional website
    date = match[2]
    data.append([email, website, date])

# Save to CSV
csv_file = 'output.csv'
with open(csv_file, 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    # Write header
    writer.writerow(['Email', 'Website', 'Date'])
    # Write rows
    writer.writerows(data)

print(f"Data has been written to {csv_file}")

Explanation:

1. Regex Breakdown:

([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}): Matches the email.

(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?: Optionally matches the website (non-capturing group with ?).

\s+(\d{1,2} [A-Za-z]{3} \d{4}): Matches the date format (e.g., 10 Jan 2024).



2. Findall:

re.findall returns a list of tuples, each containing the captured groups (email, website, and date).



3. Handling Optional Website:

If the website group is empty, it's replaced with an empty string.



4. CSV Writing:

The extracted rows are saved to a CSV file with headers.




Output:

If you run the script with the provided sample text, the generated output.csv will look like this:

This approach ensures the rows are split based on the presence of an email, optional website, and date, rather than relying on newline characters. Let me know if you have more requirements!

data.append


To ensure the first 4-5 columns aren't missed, we need to capture all data in the row while focusing on the specific columns (email, website, and date) you identified. The first columns, which might represent names or other data, can be captured as a separate group in the regex.

Hereâ€™s the updated script:

Updated Approach:

1. Capture Entire Row:

Use a regex that captures everything before the email as a single group.

Extract the first few columns along with the last three columns.



2. Adjust Regex:

Add a group for capturing all data before the email.




Updated Python Script:

import re
import csv

# Sample text from page 1
text = """
John Doe Manager Marketing john.doe@example.com www.example.com 10 Jan 2024
Jane Smith Senior Engineer jane.smith@example.com 12 Feb 2024
Adam Johnson CEO adam.j@example.com www.adamjohnson.com 23 Mar 2024
"""

# Define regex pattern to capture the entire row
row_pattern = re.compile(
    r'^(.*?\S)'  # Capture everything before the email (names and other columns)
    r'\s+([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'  # Email
    r'(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?'           # Optional website
    r'\s+(\d{1,2} [A-Za-z]{3} \d{4})$'                      # Date
)

# Extract rows using the pattern
matches = row_pattern.findall(text)

# Prepare data for CSV
data = []
for match in matches:
    other_columns = match[0]  # Everything before the email
    email = match[1]
    website = match[2] if match[2] else ""  # Handle optional website
    date = match[3]
    # Combine all columns into a single row
    row = [other_columns, email, website, date]
    data.append(row)

# Save to CSV
csv_file = 'output.csv'
with open(csv_file, 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    # Write header
    writer.writerow(['Other Columns', 'Email', 'Website', 'Date'])
    # Write rows
    writer.writerows(data)

print(f"Data has been written to {csv_file}")

Explanation:

1. Regex Breakdown:

^(.*?\S): Captures all text before the email as a single group (.*?\S ensures it captures up to the email while trimming trailing whitespace).

([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}): Captures the email.

(?:\s+(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}))?: Captures the optional website.

(\d{1,2} [A-Za-z]{3} \d{4})$: Captures the date.



2. Data Extraction:

Group 1 captures the first few columns (names and roles).

Groups 2, 3, and 4 correspond to the email, website, and date, respectively.



3. CSV Writing:

Each row includes the captured first columns, email, website, and date.




Output:

For the given sample text, the output CSV (output.csv) will look like this:

This ensures no data from the beginning of the row is lost. Let me know if further adjustments are needed!

